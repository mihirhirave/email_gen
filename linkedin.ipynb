{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f948f9",
   "metadata": {},
   "source": [
    "# Cold Email Generator for Students\n",
    "\n",
    "This notebook provides a Streamlit application to generate cold emails for students based on job postings and LinkedIn profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de99557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain_openai in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain_community in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (0.3.20)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: streamlit in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (1.43.2)\n",
      "Requirement already satisfied: requests in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_openai) (1.72.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: jinja2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.32.0)\n",
      "Requirement already satisfied: colorama in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\masterp\\projects\\cold-email-generator-for-students\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Using cached bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: C:\\masterp\\projects\\Cold-Email-Generator-for-Students\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain_openai langchain_community bs4 streamlit requests selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61589baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WebBaseLoader\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate, ChatPromptTemplate\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884d8a4",
   "metadata": {},
   "source": [
    "## LinkedIn Scraping Issues\n",
    "\n",
    "LinkedIn uses strong anti-scraping measures that prevent direct access via simple requests.\n",
    "Let's examine the issue with our current approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6275852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 999\n",
      "Response HTML (first 300 characters):\n",
      "<html><head>\n",
      "<script type=\"text/javascript\">\n",
      "window.onload = function() {\n",
      "  // Parse the tracking code from cookies.\n",
      "  var trk = \"bf\";\n",
      "  var trkInfo = \"bf\";\n",
      "  var cookies = document.cookie.split(\"; \");\n",
      "  for (var i = 0; i < cookies.length; ++i) {\n",
      "    if ((cookies[i].indexOf(\"trkCode=\") == 0) && (coo\n",
      "\n",
      "Extracted text (showing all):\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example URL for testing - showing why direct requests don't work\n",
    "url = \"https://www.linkedin.com/in/mihirhirave/\"  # replace with your actual URL\n",
    "response = requests.get(url)\n",
    "print(f\"Response status code: {response.status_code}\")\n",
    "print(\"Response HTML (first 300 characters):\")\n",
    "print(response.text[:300])\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "text = soup.get_text()\n",
    "print(\"\\nExtracted text (showing all):\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29fe66d",
   "metadata": {},
   "source": [
    "## Alternative LinkedIn Data Collection Solutions\n",
    "\n",
    "Since LinkedIn blocks direct scraping, we need alternative approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use Selenium with browser automation (requires login)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "def scrape_linkedin_with_selenium(linkedin_url):\n",
    "    \"\"\"Scrape LinkedIn with Selenium - requires manual login\"\"\"\n",
    "    # Setup Chrome options\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")  # Run headless if no manual login needed\n",
    "    \n",
    "    # Initialize the Chrome driver\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        \n",
    "        # First go to LinkedIn login page\n",
    "        driver.get(\"https://www.linkedin.com/login\")\n",
    "        print(\"Please log in to LinkedIn in the browser window.\")\n",
    "        print(\"After logging in, the script will continue automatically.\")\n",
    "        \n",
    "        # Wait for manual login (wait until URL contains 'feed' which indicates successful login)\n",
    "        max_wait = 60  # Maximum wait time in seconds\n",
    "        wait_time = 0\n",
    "        while wait_time < max_wait:\n",
    "            if \"feed\" in driver.current_url:\n",
    "                break\n",
    "            time.sleep(5)\n",
    "            wait_time += 5\n",
    "            print(f\"Waiting for login... ({wait_time} seconds)\")\n",
    "        \n",
    "        if wait_time >= max_wait:\n",
    "            print(\"Login timeout reached. Proceeding anyway...\")\n",
    "        \n",
    "        # Now navigate to the profile URL\n",
    "        print(f\"Navigating to {linkedin_url}\")\n",
    "        driver.get(linkedin_url)\n",
    "        time.sleep(5)  # Allow time for the page to load\n",
    "        \n",
    "        # Extract the page content\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        # Clean up and return\n",
    "        driver.quit()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "# Uncomment to test this function\n",
    "# profile_text = scrape_linkedin_with_selenium(\"https://www.linkedin.com/in/mihirhirave/\")\n",
    "# if profile_text:\n",
    "#     print(f\"Extracted {len(profile_text)} characters of profile text\")\n",
    "#     print(f\"Sample: {profile_text[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6df6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Alternative approach - get user to manually input their LinkedIn info\n",
    "def get_linkedin_data_from_user_input():\n",
    "    \"\"\"Get LinkedIn profile data directly from user inputs instead of scraping\"\"\"\n",
    "    # In Streamlit, these would be text inputs or text areas\n",
    "    linkedin_data = {\n",
    "        \"headline\": \"Software Engineer\",  # st.text_input(\"Your LinkedIn Headline\")\n",
    "        \"about\": \"Experienced software engineer with background in...\",  # st.text_area(\"About You\")\n",
    "        \"experience\": \"Software Engineer at Company X (2020-Present)\\nIntern at Company Y (2019-2020)\",  # st.text_area(\"Experience\")\n",
    "        \"education\": \"BS Computer Science, University Z (2016-2020)\",  # st.text_area(\"Education\")\n",
    "        \"skills\": \"Python, JavaScript, Machine Learning, Data Analysis\"  # st.text_input(\"Key Skills (comma separated)\")\n",
    "    }\n",
    "    \n",
    "    # Format the data into a string similar to what we'd get from scraping\n",
    "    formatted_data = f\"\"\"Headline: {linkedin_data['headline']}\n",
    "About: {linkedin_data['about']}\n",
    "Experience: {linkedin_data['experience']}\n",
    "Education: {linkedin_data['education']}\n",
    "Skills: {linkedin_data['skills']}\"\"\"\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "# Example of profile data format that would be returned\n",
    "example_profile_data = get_linkedin_data_from_user_input()\n",
    "print(\"Example manual profile data:\")\n",
    "print(example_profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified fetch_and_summarize function to handle LinkedIn specially\n",
    "def fetch_and_summarize(url, llm):\n",
    "    \"\"\"Fetch and summarize content from a URL, with special handling for LinkedIn\"\"\"\n",
    "    try:\n",
    "        # Check if this is a LinkedIn URL\n",
    "        if \"linkedin.com/in/\" in url:\n",
    "            # For LinkedIn, we'll use our alternative approach\n",
    "            print(\"LinkedIn URL detected. Using alternative method to get profile data...\")\n",
    "            \n",
    "            # In a real app, you would use either the Selenium approach or manual input\n",
    "            # For this demo, we'll use a mocked profile\n",
    "            profile_data = get_linkedin_data_from_user_input()\n",
    "            \n",
    "            # Since we already have the formatted data, we can skip the summarization step\n",
    "            # or still run it through the LLM to get a more concise version\n",
    "            prompt_summary = PromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Summarize the following LinkedIn profile to highlight key skills and achievements that would be relevant for job applications:\n",
    "                {content}\n",
    "                \"\"\"\n",
    "            )\n",
    "            chain_summary = prompt_summary | llm\n",
    "            summary_response = chain_summary.invoke({\"content\": profile_data})\n",
    "            return summary_response.content.strip()\n",
    "            \n",
    "        else:\n",
    "            # For non-LinkedIn URLs, use the standard approach\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "            \n",
    "            prompt_summary = PromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Summarize the following content to highlight key skills and achievements:\n",
    "                {content}\n",
    "                \"\"\"\n",
    "            )\n",
    "            chain_summary = prompt_summary | llm\n",
    "            summary_response = chain_summary.invoke({\"content\": text})\n",
    "            \n",
    "            return summary_response.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching data: {e}\"\n",
    "\n",
    "# This function would replace the fetch_and_summarize function in the main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit App Configuration\n",
    "st.set_page_config(page_title=\"Cold Email Generator for Students\", page_icon=\"ðŸ“§\", layout=\"wide\")\n",
    "\n",
    "# Custom CSS for styling\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #f0f8ff;\n",
    "        }\n",
    "        .generated-email {\n",
    "            height: 400px !important;\n",
    "            font-size: 14px;\n",
    "            font-family: Arial, sans-serif;\n",
    "        }\n",
    "        .stTextArea label {\n",
    "            font-size: 16px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .stButton button {\n",
    "            background-color: #ff4500;\n",
    "            color: white;\n",
    "            font-size: 16px;\n",
    "        }\n",
    "        .stTextInput label, .stJson label {\n",
    "            font-size: 15px;\n",
    "            color: #333;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "# Streamlit App Title and Description\n",
    "st.title(\"ðŸ“§ Cold Email Generator for Students\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    Welcome to the **Cold Email Generator for Students**! This tool helps you craft professional and tailored cold emails \n",
    "    for job applications by leveraging AI and your online profiles.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Step 1: User Inputs\n",
    "st.header(\"Step 1: Provide Input Details\")\n",
    "with st.form(\"user_inputs\"):\n",
    "    url_input = st.text_input(\"Enter the Job URL:\", placeholder=\"e.g., https://www.example.com/job-posting\")\n",
    "    student_name = st.text_input(\"Your Name:\", placeholder=\"e.g., Jane Doe\")\n",
    "    university_name = st.text_input(\"Your University/Organization:\", placeholder=\"e.g., University of Example\")\n",
    "    \n",
    "    # Modified LinkedIn input approach\n",
    "    st.markdown(\"#### LinkedIn Information\")\n",
    "    st.markdown(\"*LinkedIn profiles can't be automatically scraped due to restrictions. Please provide your details manually:*\")\n",
    "    linkedin_headline = st.text_input(\"Your Headline:\", placeholder=\"e.g., Computer Science Student at University of Example\")\n",
    "    linkedin_experience = st.text_area(\"Your Experience:\", placeholder=\"e.g., Internship at Company X (Summer 2023)\\nResearch Assistant (2022-Present)\")\n",
    "    linkedin_education = st.text_input(\"Your Education:\", placeholder=\"e.g., BS Computer Science, University of Example (2020-2024)\")\n",
    "    linkedin_skills = st.text_input(\"Your Skills:\", placeholder=\"e.g., Python, Java, Machine Learning, Web Development\")\n",
    "    \n",
    "    portfolio_url = st.text_input(\"Portfolio Website (Optional):\", placeholder=\"e.g., https://yourportfolio.com/projects\")\n",
    "    openai_api_key = st.text_input(\"OpenAI API Key (Required):\", type=\"password\")\n",
    "    generate_button = st.form_submit_button(\"Extract Job Details and Generate Email\")\n",
    "\n",
    "if generate_button:\n",
    "    if not url_input.strip() or not student_name.strip() or not university_name.strip() or not linkedin_headline.strip() or not openai_api_key.strip():\n",
    "        st.error(\"Please provide all required inputs (Job URL, Name, University/Organization, LinkedIn Headline, and OpenAI API Key).\")\n",
    "    else:\n",
    "        try:\n",
    "            # Step 1: Initialize OpenAI LLM\n",
    "            llm = ChatOpenAI(\n",
    "                temperature=0,\n",
    "                api_key=openai_api_key,\n",
    "                model_name=\"gpt-4\"\n",
    "            )\n",
    "\n",
    "            # Step 2: Scrape job description\n",
    "            st.info(\"Scraping the job page content...\")\n",
    "            loader = WebBaseLoader([url_input])\n",
    "            page_data = loader.load().pop().page_content\n",
    "\n",
    "            prompt_extract = PromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                ### SCRAPED TEXT FROM WEBSITE:\n",
    "                {page_data}\n",
    "                ### INSTRUCTION:\n",
    "                Extract the job postings in valid JSON format with keys: `role`, `experience`, `skills`, and `description`.\n",
    "                Return ONLY the JSON object without any additional text, markdown formatting, or headers.\n",
    "                The response should start directly with the JSON object.\n",
    "                \"\"\"\n",
    "            )\n",
    "            chain_extract = prompt_extract | llm\n",
    "            res = chain_extract.invoke({\"page_data\": page_data})\n",
    "            \n",
    "            # Clean up the response to extract just the JSON part\n",
    "            content = res.content\n",
    "            # Remove any markdown headers or text before the JSON\n",
    "            json_match = re.search(r'(\\[|\\{).*(\\]|\\})', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "            else:\n",
    "                json_str = content\n",
    "                \n",
    "            try:\n",
    "                # Parse the cleaned JSON string\n",
    "                job_details = json.loads(json_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                st.error(f\"Error parsing JSON: {e}\")\n",
    "                st.code(content, language=\"json\")\n",
    "                raise Exception(f\"Failed to parse job details. The API returned an invalid JSON format.\")\n",
    "\n",
    "            # Step 3: Process LinkedIn data (now from manual input instead of scraping)\n",
    "            linkedin_data = f\"\"\"Headline: {linkedin_headline}\n",
    "Experience: {linkedin_experience}\n",
    "Education: {linkedin_education}\n",
    "Skills: {linkedin_skills}\"\"\"\n",
    "            \n",
    "            # Summarize the LinkedIn data using the LLM\n",
    "            prompt_linkedin = PromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Summarize the following LinkedIn profile to highlight relevant skills and experiences for job applications:\n",
    "                {content}\n",
    "                \"\"\"\n",
    "            )\n",
    "            chain_linkedin = prompt_linkedin | llm\n",
    "            linkedin_summary = chain_linkedin.invoke({\"content\": linkedin_data}).content.strip()\n",
    "            \n",
    "            # Process portfolio if provided\n",
    "            if portfolio_url.strip():\n",
    "                st.info(\"Analyzing portfolio content...\")\n",
    "                try:\n",
    "                    # Standard web scraping approach for portfolio (assuming it's not LinkedIn)\n",
    "                    response = requests.get(portfolio_url)\n",
    "                    response.raise_for_status()\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                    text = soup.get_text()\n",
    "                    \n",
    "                    prompt_summary = PromptTemplate.from_template(\n",
    "                        \"\"\"\n",
    "                        Summarize the following content to highlight key skills and achievements:\n",
    "                        {content}\n",
    "                        \"\"\"\n",
    "                    )\n",
    "                    chain_summary = prompt_summary | llm\n",
    "                    portfolio_summary = chain_summary.invoke({\"content\": text}).content.strip()\n",
    "                except Exception as e:\n",
    "                    portfolio_summary = f\"Error fetching portfolio data: {e}. Please provide a summary manually.\"\n",
    "            else:\n",
    "                portfolio_summary = \"No portfolio provided.\"\n",
    "\n",
    "            # Step 4: Generate Cold Email\n",
    "            st.header(\"Step 2: Generate Cold Email\")\n",
    "            st.info(\"Generating cold email...\")\n",
    "            prompt_email = ChatPromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                ### JOB DESCRIPTION:\n",
    "                {job_description}\n",
    "\n",
    "                ### CANDIDATE DETAILS:\n",
    "                Name: {student_name}\n",
    "                University/Organization: {university_name}\n",
    "                LinkedIn Summary: {linkedin_summary}\n",
    "                Portfolio Summary: {portfolio_summary}\n",
    "\n",
    "                ### INSTRUCTIONS:\n",
    "                Write a professional cold email for the job description in four structured paragraphs:\n",
    "                1. Introduction of the candidate (name, background, and current affiliation).\n",
    "                2. Highlight relevant experiences and skills based on the LinkedIn and portfolio summaries.\n",
    "                3. Explain why the candidate is an excellent fit for the job.\n",
    "                4. End with a call to action for further discussion.\n",
    "\n",
    "                ### EMAIL (START HERE):\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "            chain_email = prompt_email | llm\n",
    "            email_response = chain_email.invoke(\n",
    "                {\n",
    "                    \"job_description\": str(job_details),\n",
    "                    \"student_name\": student_name,\n",
    "                    \"university_name\": university_name,\n",
    "                    \"linkedin_summary\": linkedin_summary,\n",
    "                    \"portfolio_summary\": portfolio_summary,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Display the generated email\n",
    "            st.subheader(\"Generated Cold Email\")\n",
    "            st.text_area(\"Cold Email\", email_response.content, height=400, key=\"generated_email\", help=\"Copy and customize as needed.\")\n",
    "            st.download_button(\n",
    "                label=\"ðŸ“¥ Download Email\",\n",
    "                data=email_response.content,\n",
    "                file_name=\"cold_email.txt\",\n",
    "                mime=\"text/plain\",\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bea08bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the installation worked properly\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mImport successful!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "# Test the installation worked properly\n",
    "from langchain_openai import ChatOpenAI\n",
    "print(\"Import successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262fa78c",
   "metadata": {},
   "source": [
    "## LinkedIn Scraping Explanation\n",
    "\n",
    "The original scraping approach failed because LinkedIn has anti-scraping protections in place:\n",
    "\n",
    "1. They detect and block automated requests\n",
    "2. They return a custom status code (999) and redirect to an authentication page\n",
    "3. They require cookies and JavaScript execution\n",
    "\n",
    "To solve this issue, we've implemented two alternative approaches:\n",
    "\n",
    "1. **Manual Input Method** - The simplest solution is to ask users to enter their LinkedIn details directly.\n",
    "2. **Selenium Method** - For more automated solutions, using Selenium with authentication would work but requires more setup.\n",
    "\n",
    "The current implementation uses the Manual Input Method as it's more reliable and easier to set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6c70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
